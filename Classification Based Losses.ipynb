{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### torch.rand() - samples from a uniform distribution on the interval [0, 1)\n",
    "##### torch.randn() - samples from a normal distribution with mean=0 and sigma=1\n",
    "##### torch.randint(low, high, size) - samples integers randomly from low to high-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy & NLL Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 1.0122, -0.6784, -0.4772,  0.2061],\n",
      "        [ 0.8358,  0.0491, -1.2866, -0.8148],\n",
      "        [ 2.0391, -0.1507, -0.6823,  0.3083],\n",
      "        [ 0.0897,  0.9958, -0.7984, -0.6539]]) \n",
      "Y: tensor([2, 3, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = torch.randint(0, 4, (4,))\n",
    "\n",
    "print('X:', x, '\\nY:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCE:\n",
      "\n",
      "Loss per Element: tensor([2.1082, 2.2198, 0.3037, 2.2165])\n",
      "Mean Loss: tensor(1.7120)\n",
      "\n",
      "\n",
      "NLL:\n",
      "\n",
      "Loss per Element: tensor([2.1082, 2.2198, 0.3037, 2.2165])\n",
      "Mean Loss: tensor(1.7120)\n"
     ]
    }
   ],
   "source": [
    "# torch implementation\n",
    "print('CCE:')\n",
    "print('\\nLoss per Element:', nn.CrossEntropyLoss(reduction='none')(x, y))\n",
    "print('Mean Loss:', nn.CrossEntropyLoss()(x, y))\n",
    "\n",
    "print('\\n\\nNLL:')\n",
    "print('\\nLoss per Element:', nn.NLLLoss(reduction='none')(nn.LogSoftmax(dim=1)(x), y))\n",
    "print('Mean Loss:', nn.NLLLoss()(nn.LogSoftmax(dim=1)(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: [2.10816598 2.21984363 0.30370933 2.21646667]\n",
      "Mean Loss: 1.7120463997125626\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "cce = np.zeros(x.shape[0])\n",
    "for i in range(x.shape[0]):\n",
    "    cce[i] = -np.log(np.exp(x[i][y[i]])/np.exp(x[i]).sum())\n",
    "print('Loss per Element:', cce)\n",
    "print('Mean Loss:', cce.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson-NLL-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: tensor([[-0.5860,  0.6840, -1.5116,  1.7220],\n",
      "        [-0.2024, -0.2763,  1.0518,  0.4510],\n",
      "        [ 0.2592, -1.1736, -0.9690,  0.1357],\n",
      "        [-0.5040,  0.4342,  1.3743,  1.5051]])\n",
      "\n",
      "Without Stirling approximation:\n",
      "Loss per Element: tensor([[ 3.3449,  0.9715, -0.1009,  0.8740],\n",
      "        [ 2.4757,  1.0639,  1.6295,  0.8102],\n",
      "        [ 7.1549,  0.6833, -0.1558,  1.3193],\n",
      "        [ 1.1391,  2.2746,  1.5472,  1.5042]])\n",
      "Mean Loss: tensor(1.6585)\n",
      "\n",
      "With Stirling approximation:\n",
      "Loss per Element: tensor([[ 3.3449,  0.9715, -0.1009,  1.2785],\n",
      "        [ 2.4757,  1.0639,  1.5750,  0.8102],\n",
      "        [ 7.1549,  0.6833, -0.1558,  1.3193],\n",
      "        [ 1.1391,  2.2746,  1.6878,  1.7379]])\n",
      "Mean Loss: tensor(1.7037)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randn(4, 4)\n",
    "print('Y:', target)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nWithout Stirling approximation:')\n",
    "print('Loss per Element:', nn.PoissonNLLLoss(log_input=True, reduction='none')(x, target))\n",
    "print('Mean Loss:', nn.PoissonNLLLoss(log_input=True)(x, target))\n",
    "\n",
    "print('\\nWith Stirling approximation:')\n",
    "print('Loss per Element:', nn.PoissonNLLLoss(log_input=True, reduction='none', full=True)(x, target))\n",
    "print('Mean Loss:', nn.PoissonNLLLoss(log_input=True, full=True)(x, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without Stirling approximation:\n",
      "Loss per Element: tensor([[ 3.3449,  0.9715, -0.1009,  0.8740],\n",
      "        [ 2.4757,  1.0639,  1.6295,  0.8102],\n",
      "        [ 7.1549,  0.6833, -0.1558,  1.3193],\n",
      "        [ 1.1391,  2.2746,  1.5472,  1.5042]])\n",
      "Mean Loss: tensor(1.6585)\n",
      "\n",
      "With Stirling approximation:\n",
      "Loss per Element: tensor([[ 3.3449,  0.9715, -0.1009,  1.2785],\n",
      "        [ 2.4757,  1.0639,  1.5750,  0.8102],\n",
      "        [ 7.1549,  0.6833, -0.1558,  1.3193],\n",
      "        [ 1.1391,  2.2746,  1.6878,  1.7379]])\n",
      "Mean Loss: tensor(1.7037)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-97580c9d7c9e>:7: RuntimeWarning: invalid value encountered in log\n",
      "  poisson[target>1] += (target * np.log(target) - target + 0.5*np.log(2*np.pi*target))[target>1]\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "poisson = np.exp(x) - x*target\n",
    "print('\\nWithout Stirling approximation:')\n",
    "print('Loss per Element:', poisson)\n",
    "print('Mean Loss:', poisson.mean())\n",
    "\n",
    "poisson[target>1] += (target * np.log(target) - target + 0.5*np.log(2*np.pi*target))[target>1]\n",
    "print('\\nWith Stirling approximation:')\n",
    "print('Loss per Element:', poisson)\n",
    "print('Mean Loss:', poisson.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLDivergence Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[0.6813, 0.0164, 0.6615, 0.9512],\n",
      "        [0.5952, 0.0906, 0.0625, 0.1622],\n",
      "        [0.7820, 0.8275, 0.8201, 0.6805],\n",
      "        [0.5325, 0.3463, 0.7606, 0.9412]]) \n",
      "Y: tensor([[0.6856, 0.1691, 0.8089, 0.0290],\n",
      "        [0.6198, 0.3843, 0.4747, 0.5940],\n",
      "        [0.5110, 0.6849, 0.4696, 0.6748],\n",
      "        [0.5274, 0.5670, 0.1215, 0.0474]])\n",
      "\n",
      "Loss per Element: tensor([[ 0.0043,  0.3947,  0.1627, -0.1013],\n",
      "        [ 0.0252,  0.5551,  0.9624,  0.7709],\n",
      "        [-0.2174, -0.1295, -0.2618, -0.0057],\n",
      "        [-0.0051,  0.2796, -0.2229, -0.1417]])\n",
      "Mean Loss: tensor(0.5174)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "y = torch.rand(4, 4)\n",
    "\n",
    "print('X:', x, '\\nY:', y)\n",
    "\n",
    "# As with NLLLoss, the input given is expected to contain log-probabilities\n",
    "xlog = np.log(x)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.KLDivLoss(reduction='none')(xlog, y))\n",
    "print('Mean Loss:', nn.KLDivLoss(reduction='batchmean')(xlog, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([[ 0.0043,  0.3947,  0.1627, -0.1013],\n",
      "        [ 0.0252,  0.5551,  0.9624,  0.7709],\n",
      "        [-0.2174, -0.1295, -0.2618, -0.0057],\n",
      "        [-0.0051,  0.2796, -0.2229, -0.1417]])\n",
      "Mean Loss: tensor(0.5174)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "kld = y*(np.log(y)-xlog)\n",
    "print('Loss per Element:', kld)\n",
    "print('Mean Loss:', kld.sum()/kld.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCELoss & BCEWithLogitsClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([0.4431, 0.3669, 0.5999, 0.4177]) \n",
      "Y: tensor([0., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4)\n",
    "xsig = nn.Sigmoid()(x)\n",
    "y_single_label = torch.FloatTensor(4).random_(2)\n",
    "sample_wts = torch.rand(4)\n",
    "\n",
    "print('X:', xsig, '\\nY:', y_single_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BCELoss\n",
      "\n",
      "Loss per Element: tensor([0.1490, 0.2209, 0.4339, 0.6489])\n",
      "Mean Loss: tensor(0.3632)\n",
      "\n",
      "BCEWithLogitsLoss\n",
      "\n",
      "Loss per Element: tensor([0.1490, 0.2209, 0.4339, 0.6489])\n",
      "Mean Loss: tensor(0.3632)\n"
     ]
    }
   ],
   "source": [
    "# torch implementation\n",
    "print('\\nBCELoss')\n",
    "print('\\nLoss per Element:', nn.BCELoss(reduction='none', weight=sample_wts)(xsig, y_single_label))\n",
    "print('Mean Loss:', nn.BCELoss(weight=sample_wts)(xsig, y_single_label))\n",
    "\n",
    "print('\\nBCEWithLogitsLoss')\n",
    "print('\\nLoss per Element:', nn.BCEWithLogitsLoss(reduction='none', weight=sample_wts)(x, y_single_label))\n",
    "print('Mean Loss:', nn.BCEWithLogitsLoss(weight=sample_wts)(x, y_single_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([0.1490, 0.2209, 0.4339, 0.6489])\n",
      "Mean Loss: tensor(0.3632)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "bce = -sample_wts*(y_single_label*np.log(xsig) + (1-y_single_label)*np.log(1-xsig))\n",
    "print('Loss per Element:', bce)\n",
    "print('Mean Loss:', bce.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-label w/o unbalanced class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[0.7011, 0.4829, 0.7022, 0.1409],\n",
      "        [0.3880, 0.3372, 0.2545, 0.7500],\n",
      "        [0.2334, 0.6017, 0.7131, 0.5574],\n",
      "        [0.1010, 0.3448, 0.6275, 0.9657]]) \n",
      "Y: tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "xsig = nn.Sigmoid()(x)\n",
    "y_multi_label = torch.FloatTensor(4, 4).random_(2)\n",
    "\n",
    "sample_wts = torch.rand(4)\n",
    "\n",
    "print('X:', xsig, '\\nY:', y_multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BCELoss\n",
      "\n",
      "Loss per Element: tensor([[0.3453, 0.5791, 0.5197, 0.1452],\n",
      "        [0.4775, 0.3612, 0.5870, 0.2752],\n",
      "        [1.4145, 0.8084, 0.1451, 0.5591],\n",
      "        [0.1035, 0.9350, 0.1999, 0.0333]])\n",
      "Mean Loss: tensor(0.4681)\n",
      "\n",
      "\n",
      "BCEWithLogitsLoss\n",
      "\n",
      "Loss per Element: tensor([[0.3453, 0.5791, 0.5197, 0.1452],\n",
      "        [0.4775, 0.3612, 0.5870, 0.2752],\n",
      "        [1.4145, 0.8084, 0.1451, 0.5591],\n",
      "        [0.1035, 0.9350, 0.1999, 0.0333]])\n",
      "Mean Loss: tensor(0.4681)\n"
     ]
    }
   ],
   "source": [
    "# torch implementation\n",
    "print('\\n\\nBCELoss')\n",
    "print('\\nLoss per Element:', nn.BCELoss(reduction='none', weight=sample_wts)(xsig, y_multi_label))\n",
    "print('Mean Loss:', nn.BCELoss(weight=sample_wts)(xsig, y_multi_label))\n",
    "\n",
    "print('\\n\\nBCEWithLogitsLoss')\n",
    "print('\\nLoss per Element:', nn.BCEWithLogitsLoss(reduction='none', weight=sample_wts)(x, y_multi_label))\n",
    "print('Mean Loss:', nn.BCEWithLogitsLoss(weight=sample_wts)(x, y_multi_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([[0.3453, 0.5791, 0.5197, 0.1452],\n",
      "        [0.4775, 0.3612, 0.5870, 0.2752],\n",
      "        [1.4145, 0.8084, 0.1451, 0.5591],\n",
      "        [0.1035, 0.9350, 0.1999, 0.0333]])\n",
      "Mean Loss: tensor(0.4681)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "bce = -sample_wts*(y_multi_label*np.log(xsig) + (1-y_multi_label)*np.log(1-xsig))\n",
    "print('Loss per Element:', bce)\n",
    "print('Mean Loss:', bce.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-label with unbalanced class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BCEWithLogitsLoss\n",
      "\n",
      "Loss per Element: tensor([[0.2677, 0.5791, 0.5197, 0.1452],\n",
      "        [0.4775, 0.3612, 0.3448, 0.0459],\n",
      "        [1.0968, 0.8084, 0.0852, 0.0933],\n",
      "        [0.1035, 0.6172, 0.1174, 0.0056]])\n",
      "Mean Loss: tensor(0.3543)\n"
     ]
    }
   ],
   "source": [
    "pos_wts = torch.rand(4)\n",
    "\n",
    "# Not possible with BCELoss\n",
    "\n",
    "# torch implementation\n",
    "print('\\nBCEWithLogitsLoss')\n",
    "print('\\nLoss per Element:', nn.BCEWithLogitsLoss(reduction='none', weight=sample_wts, pos_weight=pos_wts)(x, y_multi_label))\n",
    "print('Mean Loss:', nn.BCEWithLogitsLoss(weight=sample_wts, pos_weight=pos_wts)(x, y_multi_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([[0.2677, 0.5791, 0.5197, 0.1452],\n",
      "        [0.4775, 0.3612, 0.3448, 0.0459],\n",
      "        [1.0968, 0.8084, 0.0852, 0.0933],\n",
      "        [0.1035, 0.6172, 0.1174, 0.0056]])\n",
      "Mean Loss: tensor(0.3543)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "bce = -sample_wts*(pos_wts*y_multi_label*np.log(xsig) + (1-y_multi_label)*np.log(1-xsig))\n",
    "print('Loss per Element:', bce)\n",
    "print('Mean Loss:', bce.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[-1.0196,  0.8123, -1.1416, -1.8985],\n",
      "        [ 0.6518, -0.6446,  0.1760,  1.0418],\n",
      "        [-0.7584,  1.0687, -0.0389,  1.4692],\n",
      "        [-1.6708, -0.8434,  0.2748,  0.0430],\n",
      "        [ 0.5977,  1.5124, -1.1130, -0.8811],\n",
      "        [ 1.4084, -1.7454, -0.6006, -0.0891]]) \n",
      "Y: tensor([[ 0,  2, -1,  3],\n",
      "        [ 3,  1,  0,  2],\n",
      "        [ 1,  2, -1,  3],\n",
      "        [ 2,  1, -1,  3],\n",
      "        [ 1,  2,  0,  3],\n",
      "        [ 1,  0,  2,  3]])\n",
      "\n",
      "Loss per Element: tensor([1.5375, 0.0000, 1.0472, 0.7068, 0.0000, 0.0000])\n",
      "Mean Loss: tensor(0.5486)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(6, 4)\n",
    "# y = torch.LongTensor(6, 4).random_(-1, 4)\n",
    "y_choices = torch.Tensor(range(-1, x.shape[1]))\n",
    "y = torch.Tensor([np.random.choice(y_choices, (4, ), replace=False) for _ in range(x.shape[0])]).long()\n",
    "\n",
    "print('X:', x, '\\nY:', y)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.MultiLabelMarginLoss(reduction='none')(x, y))\n",
    "print('Mean Loss:', nn.MultiLabelMarginLoss()(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Found the documentation pretty confusing for this one - https://pytorch.org/docs/1.5.1/nn.html#multilabelmarginloss. My explanation below:\n",
    "##### x and y in the doc are 1D tensors though the function works for 2D as well.\n",
    "##### i indexes over x, j indexes over y: same range as y and x must have the same size.\n",
    "##### j stops when y<0 (or ==-1) is encountered.\n",
    "##### i!=y[j] for all i, j; that's captured in the variable cont_non_neg_targets below.\n",
    "##### k in code below indexes over N, the number of samples; so x[k], y[k] correspond to x and y in the doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: [1.537469   0.         1.0472248  0.70677024 0.         0.        ]\n",
      "Mean Loss: 0.54857737\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "mlm_l = np.zeros(x.shape[0], dtype=np.float32)\n",
    "for k in range(x.shape[0]):\n",
    "    loss_ele = 0\n",
    "    cont_non_neg_targets = []\n",
    "    \n",
    "    for j in range(len(y[k])):\n",
    "        if y[k, j]<0: break\n",
    "        cont_non_neg_targets.append(y[k, j])\n",
    "    \n",
    "    for i in range(len(x[k])):\n",
    "        if len(cont_non_neg_targets)>0:\n",
    "            for j in cont_non_neg_targets:\n",
    "                if i not in cont_non_neg_targets:\n",
    "                    loss_ele += max(0, 1 - (x[k, j] - x[k, i]))\n",
    "    \n",
    "    mlm_l[k] = loss_ele/len(x[k])\n",
    "\n",
    "print('Loss per Element:', mlm_l)\n",
    "print('Mean Loss:', mlm_l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MarginRankingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor([0.8117, 0.9745, 0.3043, 0.8968, 0.6093, 0.2207]) \n",
      "x2: tensor([0.4264, 0.9011, 0.8347, 0.0628, 0.1673, 0.3796]) \n",
      "y: tensor([ 1., -1.,  1., -1.,  1.,  1.])\n",
      "\n",
      "Loss per Element: tensor([0.1147, 0.5735, 1.0303, 1.3340, 0.0580, 0.6589])\n",
      "Mean Loss: tensor(0.6282)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(6)\n",
    "x2 = torch.rand(6)\n",
    "y_choices = torch.Tensor([1, -1])\n",
    "y = y_choices[torch.randint(len(y_choices), (len(x1),))]\n",
    "margin = 0.5\n",
    "\n",
    "print('x1:', x1, '\\nx2:', x2, '\\ny:', y)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.MarginRankingLoss(margin=margin, reduction='none')(x1, x2, y))\n",
    "print('Mean Loss:', nn.MarginRankingLoss(margin=margin)(x1, x2, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([0.1147, 0.5735, 1.0303, 1.3340, 0.0580, 0.6589])\n",
      "Mean Loss: tensor(0.6282)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "ranking_l = np.clip(-y*(x1-x2) + margin, a_min=0, a_max=None)\n",
    "print('Loss per Element:', ranking_l)\n",
    "print('Mean Loss:', ranking_l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HingeEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss per Element: tensor([0.8117, 0.0000, 0.3043, 0.0000, 0.6093, 0.2207])\n",
      "Mean Loss: tensor(0.3243)\n"
     ]
    }
   ],
   "source": [
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.HingeEmbeddingLoss(margin=margin, reduction='none')(x1, y))\n",
    "print('Mean Loss:', nn.HingeEmbeddingLoss(margin=margin)(x1, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([0.8117, 0.0000, 0.3043, 0.0000, 0.6093, 0.2207])\n",
      "Mean Loss: tensor(0.3243)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "hinge = x1\n",
    "hinge[y==-1] = (np.clip(margin-x1, a_min=0, a_max=None))[y==-1]\n",
    "print('Loss per Element:', hinge)\n",
    "print('Mean Loss:', hinge.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelSoftMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[-0.3800,  1.0549, -1.0730, -0.1902],\n",
      "        [ 0.0697,  0.5335, -0.3867,  0.3889],\n",
      "        [-0.4021, -1.9058,  0.3312,  0.4127],\n",
      "        [ 0.2506,  0.1345, -0.0142, -0.2597],\n",
      "        [ 1.3403,  2.2513, -0.8659, -0.0038],\n",
      "        [ 1.1053,  1.2902,  0.9825, -0.1717]]) \n",
      "Y: tensor([[0., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "\n",
      "Loss per Element: tensor([0.6974, 0.6358, 1.0874, 0.6154, 1.4581, 1.2520])\n",
      "Mean Loss: tensor(0.9577)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(6, 4)\n",
    "y = torch.FloatTensor(6, 4).random_(2)\n",
    "print('X:', x, '\\nY:', y)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.MultiLabelSoftMarginLoss(reduction='none')(x, y))\n",
    "print('Mean Loss:', nn.MultiLabelSoftMarginLoss()(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([0.6974, 0.6358, 1.0874, 0.6154, 1.4581, 1.2520])\n",
      "Mean Loss: tensor(0.9577)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "mlsm_l = (y*np.log(1/(1 + np.exp(-x))) + (1-y)*np.log(np.exp(-x)/(1 + np.exp(-x))))/(-x.shape[1])\n",
    "mlsm_l = mlsm_l.sum(axis=1)\n",
    "print('Loss per Element:', mlsm_l)\n",
    "print('Mean Loss:', mlsm_l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[0.2943, 0.8297, 0.3987, 0.5874, 0.8499, 0.7911],\n",
      "        [0.2872, 0.5321, 0.3106, 0.9681, 0.0945, 0.5349],\n",
      "        [0.8597, 0.5731, 0.8170, 0.6084, 0.5536, 0.5601],\n",
      "        [0.1298, 0.5443, 0.2394, 0.8772, 0.0049, 0.0089]]) \n",
      "Y: tensor([[-1., -1.,  1., -1.,  1.,  1.],\n",
      "        [ 1.,  1., -1., -1., -1.,  1.],\n",
      "        [ 1., -1., -1.,  1.,  1.,  1.],\n",
      "        [-1., -1., -1., -1., -1.,  1.]])\n",
      "\n",
      "Loss per Element: tensor([[0.8511, 1.1917, 0.5135, 1.0294, 0.3559, 0.3739],\n",
      "        [0.5598, 0.4621, 0.8605, 1.2900, 0.7415, 0.4611],\n",
      "        [0.3530, 1.0202, 1.1828, 0.4345, 0.4542, 0.4518],\n",
      "        [0.7602, 1.0019, 0.8200, 1.2250, 0.6956, 0.6887]])\n",
      "Mean Loss: tensor(0.7408)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 6)\n",
    "y_choices = torch.Tensor([1, -1])\n",
    "y = y_choices[torch.randint(len(y_choices), (x.shape[0], x.shape[1]))]\n",
    "\n",
    "print('X:', x, '\\nY:', y)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.SoftMarginLoss(reduction='none')(x, y))\n",
    "print('Mean Loss:', nn.SoftMarginLoss()(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([[0.8511, 1.1917, 0.5135, 1.0294, 0.3559, 0.3739],\n",
      "        [0.5598, 0.4621, 0.8605, 1.2900, 0.7415, 0.4611],\n",
      "        [0.3530, 1.0202, 1.1828, 0.4345, 0.4542, 0.4518],\n",
      "        [0.7602, 1.0019, 0.8200, 1.2250, 0.6956, 0.6887]])\n",
      "Mean Loss: tensor(0.7408)\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "smloss = np.log(1 + np.exp(-y*x))\n",
    "print('Loss per Element:', smloss)\n",
    "print('Mean Loss:', smloss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tensor([[0.6965, 0.2198, 0.9593],\n",
      "        [0.4978, 0.7715, 0.9826],\n",
      "        [0.0248, 0.8703, 0.3042],\n",
      "        [0.4056, 0.8449, 0.4021],\n",
      "        [0.1218, 0.6030, 0.0039],\n",
      "        [0.8904, 0.7904, 0.5569]]) \n",
      "x2: tensor([[0.1880, 0.5525, 0.5761],\n",
      "        [0.8281, 0.0927, 0.4129],\n",
      "        [0.8989, 0.6844, 0.4363],\n",
      "        [0.5131, 0.6720, 0.9893],\n",
      "        [0.7900, 0.7059, 0.3628],\n",
      "        [0.9239, 0.3779, 0.1682]]) \n",
      "y: tensor([-1., -1., -1.,  1., -1., -1.])\n",
      "\n",
      "Loss per Element: tensor([0.6142, 0.5112, 0.4720, 0.1157, 0.5596, 0.7132])\n",
      "Mean Loss: tensor(0.4977)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.rand(6, 3)\n",
    "x2 = torch.rand(6, 3)\n",
    "y_choices = torch.Tensor([1, -1])\n",
    "y = y_choices[torch.randint(len(y_choices), (len(x1),))]\n",
    "margin = 0.2\n",
    "\n",
    "print('x1:', x1, '\\nx2:', x2, '\\ny:', y)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.CosineEmbeddingLoss(margin=margin, reduction='none')(x1, x2, y))\n",
    "print('Mean Loss:', nn.CosineEmbeddingLoss(margin=margin)(x1, x2, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: [0.61423074 0.51118069 0.47203498 0.11568004 0.55964606 0.71316324]\n",
      "Mean Loss: 0.4976559579372406\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "cos_emb_l = np.zeros(x1.shape[0])\n",
    "for i in range(cos_emb_l.shape[0]):\n",
    "    cos_emb_l[i] = cosine(x1[i].numpy(), x2[i].numpy()) if y[i]==1 else max(0, 1-cosine(x1[i].numpy(), x2[i].numpy())-margin)\n",
    "\n",
    "print('Loss per Element:', cos_emb_l)\n",
    "print('Mean Loss:', cos_emb_l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 0.3148,  0.7408, -0.2145,  1.0087],\n",
      "        [ 1.9221,  0.0741, -0.6381, -0.3867],\n",
      "        [-0.6045,  0.8229,  0.2759,  0.2721],\n",
      "        [-0.7059, -0.2502,  0.8719,  1.1585],\n",
      "        [-1.1585, -0.4801,  1.6348, -1.8812],\n",
      "        [-0.9168, -1.4287,  0.9173,  1.4184],\n",
      "        [-0.2423,  0.1271, -3.1706, -1.2293],\n",
      "        [ 0.3333,  1.2549,  0.7563, -0.8989]]) \n",
      "Y: tensor([0, 3, 2, 2, 1, 3, 2, 2])\n",
      "\n",
      "Loss per Element: tensor([ 1.2811,  3.4105,  0.8499,  0.4138,  2.4514,  0.0622, 10.6381,  0.6447])\n",
      "Mean Loss: tensor(2.4690)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 4)\n",
    "y = torch.randint(0, 4, (8,))\n",
    "\n",
    "margin = 1\n",
    "p = 2\n",
    "class_wts = torch.ones(4)\n",
    "\n",
    "print('X:', x, '\\nY:', y)\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.MultiMarginLoss(reduction='none', margin=margin, p=p, weight=class_wts)(x, y))\n",
    "print('Mean Loss:', nn.MultiMarginLoss(margin=margin, p=p, weight=class_wts)(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2810552   3.4104855   0.849915    0.4138348   2.4514422   0.06221414\n",
      " 10.638116    0.64472604]\n",
      "2.4689736\n"
     ]
    }
   ],
   "source": [
    "# numpy implementation\n",
    "mml = np.zeros(x.shape[0], dtype=np.float32)\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    loss_ele = 0\n",
    "    for j in range(x.shape[1]):\n",
    "        if j!=y[i]:\n",
    "            loss_ele += max(0, class_wts[y[i]]*(margin - x[i, y[i]] + x[i, j]))**p\n",
    "    mml[i] = loss_ele/x.shape[1]\n",
    "\n",
    "print(mml)\n",
    "print(mml.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TripletMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss per Element: tensor([0.9923, 0.0924, 3.0348, 0.0000, 0.8075, 1.6179, 0.8449, 2.4973])\n",
      "Mean Loss: tensor(1.2359)\n"
     ]
    }
   ],
   "source": [
    "anchor = torch.randn(8, 4)\n",
    "positive = torch.randn(8, 4)\n",
    "negative = torch.randn(8, 4)\n",
    "\n",
    "margin = 1\n",
    "p = 2\n",
    "\n",
    "# torch implementation\n",
    "print('\\nLoss per Element:', nn.TripletMarginLoss(reduction='none', margin=margin, p=p)(anchor, positive, negative))\n",
    "print('Mean Loss:', nn.TripletMarginLoss(margin=margin, p=p)(anchor, positive, negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss per Element: tensor([0.9923, 0.0924, 3.0348, 0.0000, 0.8075, 1.6179, 0.8449, 2.4973])\n",
      "Mean Loss: tensor(1.2359)\n"
     ]
    }
   ],
   "source": [
    "def p_norm_dist(x1, x2, p):\n",
    "    d = ((x1-x2)**p).sum(axis=1)\n",
    "    return d**(1/p)\n",
    "\n",
    "# numpy implementation\n",
    "triplet_l = np.clip(p_norm_dist(anchor, positive, p) - p_norm_dist(anchor, negative, p) + margin, a_min=0, a_max=None)\n",
    "print('Loss per Element:', triplet_l)\n",
    "print('Mean Loss:', triplet_l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
